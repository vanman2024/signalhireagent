import pytest
pytest.skip("Skipped in API-only mode due to legacy module dependencies", allow_module_level=True)
"""
Integration tests for error handling and resilience

These tests MUST FAIL initially (RED phase) before implementing error handling.
Tests verify comprehensive error handling across all services and scenarios.
"""

import pytest
import asyncio
import json
import tempfile
from pathlib import Path
from unittest.mock import AsyncMock, MagicMock, patch
from src.services.search_service import SearchService
from src.services.reveal_service import RevealService
from src.services.export_service import ExportService
from src.lib.signalhire_client import SignalHireClient
from src.lib.browser_client import BrowserClient
from src.models.search_criteria import SearchCriteria
from src.models.exceptions import (
    SignalHireAPIError,
    RateLimitExceededError,
    InsufficientCreditsError,
    BrowserAutomationError,
    NetworkTimeoutError,
    AuthenticationError
)


class TestErrorHandlingIntegration:
    """Test comprehensive error handling integration"""

    @pytest.fixture
    def search_criteria(self):
        """Sample search criteria for error testing"""
        return SearchCriteria(
            title="Software Engineer",
            location="San Francisco",
            size=20
        )

    @pytest.fixture
    def temp_output_dir(self):
        """Create temporary directory for error testing"""
        import tempfile
        import shutil
        temp_dir = tempfile.mkdtemp()
        yield temp_dir
        shutil.rmtree(temp_dir, ignore_errors=True)

    @pytest.mark.integration
    @pytest.mark.asyncio
    async def test_api_error_handling_and_recovery(self, search_criteria):
        """Test API error handling with automatic recovery"""
        
        with patch('src.lib.signalhire_client.SignalHireClient') as MockClient:
            mock_client = MockClient.return_value
            
            # Simulate API error sequence: fail, fail, succeed
            error_sequence = [
                SignalHireAPIError("Internal Server Error", status_code=500),
                SignalHireAPIError("Service Unavailable", status_code=503),
                MagicMock(operation_id="recovered_search_123", prospects=[])
            ]
            
            call_count = 0
            async def mock_search_with_recovery(*args, **kwargs):
                nonlocal call_count
                if call_count < len(error_sequence) - 1:
                    error = error_sequence[call_count]
                    call_count += 1
                    if isinstance(error, Exception):
                        raise error
                call_count += 1
                return error_sequence[-1]
            
            mock_client.search = AsyncMock(side_effect=mock_search_with_recovery)
            
            # Initialize service with error recovery
            search_service = SearchService(
                client=mock_client,
                max_retries=3,
                retry_delay=0.1,
                exponential_backoff=True
            )
            
            # Execute search with error recovery
            search_result = await search_service.search(search_criteria)
            
            # Verify error recovery
            assert search_result is not None
            assert search_result.operation_id == "recovered_search_123"
            assert call_count == 3  # 2 failures + 1 success
            
            # Note: Will fail until error recovery is implemented

    @pytest.mark.integration
    @pytest.mark.asyncio
    async def test_rate_limit_error_handling(self, search_criteria):
        """Test rate limit error handling with intelligent backoff"""
        
        with patch('src.lib.signalhire_client.SignalHireClient') as MockClient:
            mock_client = MockClient.return_value
            
            # Simulate rate limit errors with retry-after headers
            rate_limit_sequence = [
                RateLimitExceededError("Rate limit exceeded", retry_after=5),
                RateLimitExceededError("Rate limit exceeded", retry_after=10),
                MagicMock(operation_id="rate_limit_recovered", prospects=[])
            ]
            
            call_count = 0
            async def mock_search_with_rate_limits(*args, **kwargs):
                nonlocal call_count
                if call_count < len(rate_limit_sequence) - 1:
                    error = rate_limit_sequence[call_count]
                    call_count += 1
                    if isinstance(error, Exception):
                        raise error
                call_count += 1
                return rate_limit_sequence[-1]
            
            mock_client.search = AsyncMock(side_effect=mock_search_with_rate_limits)
            
            # Initialize service with rate limit handling
            search_service = SearchService(
                client=mock_client,
                handle_rate_limits=True,
                max_rate_limit_retries=3
            )
            
            # Execute search with rate limit handling
            import time
            start_time = time.time()
            
            search_result = await search_service.search(search_criteria)
            
            end_time = time.time()
            execution_time = end_time - start_time
            
            # Verify rate limit handling
            assert search_result is not None
            assert execution_time >= 15  # Should wait for retry-after periods
            assert call_count == 3
            
            # Note: Will fail until rate limit handling is implemented

    @pytest.mark.integration
    @pytest.mark.asyncio
    async def test_insufficient_credits_error_handling(self):
        """Test insufficient credits error handling and user notification"""
        
        with patch('src.lib.signalhire_client.SignalHireClient') as MockClient:
            mock_client = MockClient.return_value
            
            # Mock credits check and reveal with insufficient credits
            mock_client.get_credits_balance = AsyncMock()
            mock_client.get_credits_balance.return_value = MagicMock(
                available_credits=5,  # Low credits
                used_credits=995,
                plan_type="Free"
            )
            
            async def mock_reveal_insufficient_credits(*args, **kwargs):
                raise InsufficientCreditsError(
                    "Insufficient credits for operation",
                    required_credits=50,
                    available_credits=5
                )
            
            mock_client.reveal_contacts = AsyncMock(side_effect=mock_reveal_insufficient_credits)
            
            # Initialize service with credits handling
            reveal_service = RevealService(
                client=mock_client,
                check_credits_before_operation=True,
                credits_threshold=10
            )
            
            # Execute reveal operation with insufficient credits
            error_captured = None
            try:
                await reveal_service.reveal_contacts(
                    prospect_uids=["p001", "p002", "p003"],
                    include_phone=True
                )
            except InsufficientCreditsError as e:
                error_captured = e
            
            # Verify credits error handling
            assert error_captured is not None
            assert error_captured.required_credits == 50
            assert error_captured.available_credits == 5
            assert mock_client.get_credits_balance.call_count >= 1
            
            # Note: Will fail until credits error handling is implemented

    @pytest.mark.integration
    @pytest.mark.asyncio
    async def test_browser_automation_error_recovery(self, search_criteria):
        """Test browser automation error recovery and fallback strategies"""
        
        with patch('src.lib.browser_client.BrowserClient') as MockBrowser:
            mock_browser = MockBrowser.return_value
            
            # Simulate browser automation errors
            browser_error_sequence = [
                BrowserAutomationError("Element not found: search button"),
                BrowserAutomationError("Page timeout: search results"),
                MagicMock(total_count=100, prospects=[])
            ]
            
            call_count = 0
            async def mock_browser_with_errors(*args, **kwargs):
                nonlocal call_count
                if call_count < len(browser_error_sequence) - 1:
                    error = browser_error_sequence[call_count]
                    call_count += 1
                    if isinstance(error, Exception):
                        raise error
                call_count += 1
                return browser_error_sequence[-1]
            
            mock_browser.execute_search = AsyncMock(side_effect=mock_browser_with_errors)
            mock_browser.recover_from_error = AsyncMock()
            mock_browser.take_screenshot = AsyncMock()
            
            # Initialize browser client with error recovery
            browser_client = BrowserClient(
                max_retries=3,
                retry_delay=0.1,
                enable_error_recovery=True,
                capture_screenshots_on_error=True
            )
            
            # Execute search with browser error recovery
            search_result = await browser_client.execute_search(search_criteria)
            
            # Verify browser error recovery
            assert search_result is not None
            assert search_result.total_count == 100
            assert mock_browser.recover_from_error.call_count >= 2
            assert mock_browser.take_screenshot.call_count >= 2  # Screenshots on errors
            
            # Note: Will fail until browser error recovery is implemented

    @pytest.mark.integration
    @pytest.mark.asyncio
    async def test_network_timeout_error_handling(self, search_criteria):
        """Test network timeout error handling with progressive timeouts"""
        
        with patch('src.lib.signalhire_client.SignalHireClient') as MockClient:
            mock_client = MockClient.return_value
            
            # Simulate network timeout errors
            timeout_sequence = [
                NetworkTimeoutError("Request timeout after 30s"),
                NetworkTimeoutError("Request timeout after 60s"),
                MagicMock(operation_id="timeout_recovered", prospects=[])
            ]
            
            call_count = 0
            async def mock_search_with_timeouts(*args, **kwargs):
                nonlocal call_count
                if call_count < len(timeout_sequence) - 1:
                    error = timeout_sequence[call_count]
                    call_count += 1
                    if isinstance(error, Exception):
                        raise error
                call_count += 1
                return timeout_sequence[-1]
            
            mock_client.search = AsyncMock(side_effect=mock_search_with_timeouts)
            
            # Initialize service with timeout handling
            search_service = SearchService(
                client=mock_client,
                initial_timeout=30,
                max_timeout=120,
                timeout_multiplier=2.0,
                max_retries=3
            )
            
            # Execute search with timeout handling
            search_result = await search_service.search(search_criteria)
            
            # Verify timeout handling
            assert search_result is not None
            assert call_count == 3
            
            # Verify progressive timeout increases
            # (30s, 60s, 120s timeouts should have been attempted)
            
            # Note: Will fail until timeout handling is implemented

    @pytest.mark.integration
    @pytest.mark.asyncio
    async def test_authentication_error_handling(self, search_criteria):
        """Test authentication error handling with re-authentication"""
        
        with patch('src.lib.signalhire_client.SignalHireClient') as MockClient, \
             patch('src.lib.browser_client.BrowserClient') as MockBrowser:
            
            mock_client = MockClient.return_value
            mock_browser = MockBrowser.return_value
            
            # Simulate authentication errors
            auth_error_sequence = [
                AuthenticationError("Invalid token", status_code=401),
                AuthenticationError("Token expired", status_code=401),
                MagicMock(operation_id="auth_recovered", prospects=[])
            ]
            
            call_count = 0
            async def mock_search_with_auth_errors(*args, **kwargs):
                nonlocal call_count
                if call_count < len(auth_error_sequence) - 1:
                    error = auth_error_sequence[call_count]
                    call_count += 1
                    if isinstance(error, Exception):
                        raise error
                call_count += 1
                return auth_error_sequence[-1]
            
            mock_client.search = AsyncMock(side_effect=mock_search_with_auth_errors)
            
            # Mock re-authentication
            mock_client.refresh_token = AsyncMock()
            mock_browser.login = AsyncMock()
            
            # Initialize service with authentication handling
            search_service = SearchService(
                client=mock_client,
                browser_client=mock_browser,
                handle_auth_errors=True,
                max_auth_retries=2
            )
            
            # Execute search with authentication error handling
            search_result = await search_service.search(search_criteria)
            
            # Verify authentication error handling
            assert search_result is not None
            assert mock_client.refresh_token.call_count >= 2  # Re-authentication attempts
            assert call_count == 3
            
            # Note: Will fail until authentication error handling is implemented

    @pytest.mark.integration
    @pytest.mark.asyncio
    async def test_data_validation_error_handling(self, temp_output_dir):
        """Test data validation error handling and data sanitization"""
        
        # Create malformed data file
        malformed_data_file = Path(temp_output_dir) / "malformed_data.json"
        malformed_data = {
            "prospects": [
                {
                    "uid": "valid_prospect_123",
                    "full_name": "John Doe",
                    "email_work": "john@example.com"
                },
                {
                    "uid": "",  # Invalid: empty UID
                    "full_name": None,  # Invalid: null name
                    "email_work": "invalid-email"  # Invalid: malformed email
                },
                {
                    "uid": "another_valid_prospect_456",
                    "full_name": "Jane Smith",
                    "email_work": "jane@example.com"
                }
            ]
        }
        
        with open(malformed_data_file, 'w') as f:
            json.dump(malformed_data, f)
        
        # Initialize export service with data validation
        export_service = ExportService(
            validate_data=True,
            sanitize_data=True,
            skip_invalid_records=True
        )
        
        # Execute export with data validation
        output_file = Path(temp_output_dir) / "validated_export.csv"
        
        export_result = await export_service.export_to_csv(
            input_file=str(malformed_data_file),
            output_file=str(output_file),
            include_contacts=True
        )
        
        # Verify data validation handling
        assert export_result is not None
        assert export_result.records_processed == 3
        assert export_result.valid_records == 2  # Only 2 valid records
        assert export_result.invalid_records == 1  # 1 invalid record skipped
        assert output_file.exists()
        
        # Note: Will fail until data validation is implemented

    @pytest.mark.integration
    @pytest.mark.asyncio
    async def test_file_system_error_handling(self, temp_output_dir):
        """Test file system error handling and recovery"""
        
        # Test scenarios: permission denied, disk full, invalid path
        
        with patch('src.services.export_service.ExportService') as MockExport:
            mock_export = MockExport.return_value
            
            # Simulate file system errors
            fs_error_sequence = [
                PermissionError("Permission denied: /protected/file.csv"),
                OSError("No space left on device"),
                MagicMock(file_path="/tmp/export_success.csv", records_exported=100)
            ]
            
            call_count = 0
            async def mock_export_with_fs_errors(*args, **kwargs):
                nonlocal call_count
                if call_count < len(fs_error_sequence) - 1:
                    error = fs_error_sequence[call_count]
                    call_count += 1
                    if isinstance(error, Exception):
                        raise error
                call_count += 1
                return fs_error_sequence[-1]
            
            mock_export.export_to_csv = AsyncMock(side_effect=mock_export_with_fs_errors)
            
            # Initialize service with file system error handling
            export_service = ExportService(
                fallback_directory=temp_output_dir,
                auto_retry_on_fs_error=True,
                max_fs_retries=3
            )
            
            # Execute export with file system error handling
            export_result = await export_service.export_to_csv(
                prospects=[{"uid": "p001", "name": "Test"}],
                output_file="/protected/file.csv"  # Will fail
            )
            
            # Verify file system error handling
            assert export_result is not None
            assert "/tmp/export_success.csv" in export_result.file_path
            assert call_count == 3
            
            # Note: Will fail until file system error handling is implemented

    @pytest.mark.integration
    @pytest.mark.asyncio
    async def test_concurrent_operation_error_isolation(self, search_criteria):
        """Test error isolation in concurrent operations"""
        
        with patch('src.lib.signalhire_client.SignalHireClient') as MockClient:
            mock_client = MockClient.return_value
            
            # Create mixed success/failure operations
            async def mock_operation_with_mixed_results(operation_id):
                if operation_id % 3 == 0:
                    raise SignalHireAPIError(f"API Error for operation {operation_id}")
                elif operation_id % 5 == 0:
                    raise NetworkTimeoutError(f"Timeout for operation {operation_id}")
                else:
                    return MagicMock(
                        operation_id=f"success_{operation_id}",
                        prospects=[]
                    )
            
            # Initialize service with error isolation
            search_service = SearchService(
                client=mock_client,
                isolate_errors=True,
                continue_on_partial_failure=True
            )
            
            # Execute concurrent operations
            tasks = []
            for i in range(15):
                mock_client.search = AsyncMock(
                    side_effect=lambda *args, op_id=i, **kwargs: mock_operation_with_mixed_results(op_id)
                )
                
                task = search_service.search(search_criteria)
                tasks.append(task)
            
            # Execute all operations concurrently
            results = await asyncio.gather(*tasks, return_exceptions=True)
            
            # Verify error isolation
            successful_results = [r for r in results if not isinstance(r, Exception)]
            failed_results = [r for r in results if isinstance(r, Exception)]
            
            # Should have mix of successes and failures
            assert len(successful_results) > 5  # Some operations succeed
            assert len(failed_results) > 3      # Some operations fail
            
            # Failures should not affect successful operations
            total_operations = len(successful_results) + len(failed_results)
            assert total_operations == 15
            
            # Note: Will fail until error isolation is implemented

    @pytest.mark.integration
    @pytest.mark.asyncio
    async def test_error_reporting_and_logging(self, search_criteria, temp_output_dir):
        """Test comprehensive error reporting and logging"""
        
        # Setup error logging
        error_log_file = Path(temp_output_dir) / "error_log.json"
        
        with patch('src.lib.signalhire_client.SignalHireClient') as MockClient:
            mock_client = MockClient.return_value
            
            # Simulate various error types
            errors_to_simulate = [
                SignalHireAPIError("Internal Server Error", status_code=500),
                RateLimitExceededError("Rate limit exceeded", retry_after=30),
                InsufficientCreditsError("Insufficient credits", required_credits=50, available_credits=10),
                NetworkTimeoutError("Request timeout after 60s"),
                AuthenticationError("Token expired", status_code=401)
            ]
            
            error_index = 0
            async def mock_search_with_various_errors(*args, **kwargs):
                nonlocal error_index
                if error_index < len(errors_to_simulate):
                    error = errors_to_simulate[error_index]
                    error_index += 1
                    raise error
                return MagicMock(operation_id="final_success", prospects=[])
            
            mock_client.search = AsyncMock(side_effect=mock_search_with_various_errors)
            
            # Initialize service with comprehensive error logging
            search_service = SearchService(
                client=mock_client,
                enable_error_logging=True,
                error_log_file=str(error_log_file),
                log_level="DEBUG",
                max_retries=6  # Allow all errors to be encountered
            )
            
            # Execute search with error logging
            try:
                search_result = await search_service.search(search_criteria)
            except Exception:
                pass  # We expect some errors
            
            # Verify error logging
            assert error_log_file.exists()
            
            with open(error_log_file, 'r') as f:
                error_logs = [json.loads(line) for line in f if line.strip()]
            
            # Should have logged all error types
            assert len(error_logs) >= 5
            
            # Verify error log structure
            for log_entry in error_logs:
                assert "timestamp" in log_entry
                assert "error_type" in log_entry
                assert "error_message" in log_entry
                assert "context" in log_entry
                assert "operation" in log_entry
            
            # Note: Will fail until error logging is implemented

    @pytest.mark.integration
    @pytest.mark.asyncio
    async def test_graceful_degradation_on_errors(self, search_criteria):
        """Test graceful degradation when services are unavailable"""
        
        with patch('src.lib.signalhire_client.SignalHireClient') as MockClient, \
             patch('src.lib.browser_client.BrowserClient') as MockBrowser:
            
            mock_client = MockClient.return_value
            mock_browser = MockBrowser.return_value
            
            # Simulate API completely unavailable
            mock_client.search = AsyncMock(side_effect=SignalHireAPIError("Service Unavailable", status_code=503))
            
            # But browser automation works
            mock_browser.execute_search = AsyncMock()
            mock_browser.execute_search.return_value = MagicMock(
                total_count=75,
                prospects=[{"uid": "browser_p001"}]
            )
            
            # Initialize service with graceful degradation
            search_service = SearchService(
                client=mock_client,
                browser_client=mock_browser,
                enable_graceful_degradation=True,
                fallback_to_browser=True
            )
            
            # Execute search with graceful degradation
            search_result = await search_service.search(search_criteria)
            
            # Verify graceful degradation
            assert search_result is not None
            assert search_result.total_count == 75
            assert search_result.prospects[0]["uid"] == "browser_p001"
            
            # Should have attempted API first, then fallen back to browser
            assert mock_client.search.call_count >= 1
            assert mock_browser.execute_search.call_count == 1
            
            # Note: Will fail until graceful degradation is implemented

    @pytest.mark.integration
    @pytest.mark.asyncio
    async def test_error_recovery_state_persistence(self, search_criteria, temp_output_dir):
        """Test error recovery state persistence across restarts"""
        
        # State file for recovery persistence
        recovery_state_file = Path(temp_output_dir) / "recovery_state.json"
        
        with patch('src.lib.signalhire_client.SignalHireClient') as MockClient:
            mock_client = MockClient.return_value
            
            # Simulate persistent operation that fails and needs recovery
            mock_client.search = AsyncMock(side_effect=NetworkTimeoutError("Persistent timeout"))
            
            # Initialize service with state persistence
            search_service = SearchService(
                client=mock_client,
                enable_state_persistence=True,
                recovery_state_file=str(recovery_state_file),
                max_retries=2
            )
            
            # Execute operation that will fail and save state
            try:
                await search_service.search(search_criteria)
            except NetworkTimeoutError:
                pass  # Expected failure
            
            # Verify recovery state was saved
            assert recovery_state_file.exists()
            
            with open(recovery_state_file, 'r') as f:
                recovery_state = json.load(f)
            
            assert "operation_id" in recovery_state
            assert "retry_count" in recovery_state
            assert "last_error" in recovery_state
            assert recovery_state["retry_count"] >= 2
            
            # Simulate service restart and recovery
            mock_client.search = AsyncMock()  # Now works
            mock_client.search.return_value = MagicMock(
                operation_id="recovered_after_restart",
                prospects=[]
            )
            
            # New service instance should recover from saved state
            search_service_new = SearchService(
                client=mock_client,
                enable_state_persistence=True,
                recovery_state_file=str(recovery_state_file)
            )
            
            # Should recover and complete the operation
            search_result = await search_service_new.recover_from_saved_state()
            
            # Verify recovery from saved state
            assert search_result is not None
            assert search_result.operation_id == "recovered_after_restart"
            
            # Note: Will fail until state persistence is implemented

# These integration tests MUST initially fail because the implementation doesn't exist yet.
# This is the RED phase of TDD - tests fail first, then we implement to make them pass.
import pytest
pytest.skip("Skipped in API-only mode due to legacy module dependencies", allow_module_level=True)
